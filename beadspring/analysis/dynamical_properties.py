from itertools import product

import numpy as np
from scipy.interpolate import interp1d
from scipy.optimize import curve_fit
from scipy.special import gammainc


def compute_msd(positions, per_particle=False):
    """
    Computes the mean squared displacement and the mean squared displacement per particle
    for a given trajectory. Note that you have to provide unwrapped coordinates.

    Parameters
    ----------
    positions : np.ndarray
        trajectory array with the shape (traj_length, N, 3)
    per_particle : bool
        If True, returns the mean squared displacement per particle.
        Default is False

    Returns
    -------
    msd : np.ndarray
        Mean squared displacement -> len (traj_length)
    msd_pp : np.ndarray
        MSD per particle -> shape(traj_length, N)
    """

    dx2 = np.sum((positions[1:] - positions[0]) ** 2, axis=2)  # MSD per particle
    msd = np.mean(dx2, axis=1)

    if per_particle:
        return msd, dx2
    else:
        return msd


def compute_ngp(positions):
    """
    Computes the non-Gaussian parameter for a given trajectory.
    Note that you have to provide unwrapped coordinates.

    Parameters
    ----------
    positions : np.ndarray
        trajectory array with the shape (traj_length, N, 3)

    Returns
    -------
    ngp : np.ndarray
        Non-Gaussian parameter -> len (traj_length)
    """
    dx2 = np.sum((positions[1:] - positions[0]) ** 2, axis=2) # MSD per particle
    dx4 = np.sum((positions[1:] - positions[0]) ** 4, axis=2)

    dr2 = np.mean(dx2, axis=1)  # note that this is the MSD
    dr4 = np.mean(dx4, axis=1)

    ngp = 3.0 * dr4 / (5.0 * dr2**2) - 1.0
    return ngp


def compute_debye_waller_factor(time_log, msd, tau_p=3.0):
    """
    Computes the Debye-Wallar factor from the mean squared displacement.
    The choice of time scale is set to be at 3 tau by default.

    Parameters
    ----------
    time_log : np.ndarray
        Logarithmically saved simulation times.
    msd : np.ndarray
        Mean squared displacement computed from
        logarithmically saved trajectories.

    Returns
    -------
    dwf : float
        Mean squared displacement evaluated at 3 tau

    """
    tau_p = np.where(time_log == tau_p)[0][0]
    dwf = msd[tau_p]
    return dwf


def compute_van_hove_correlation(positions, time_log, bins=100, rmax=8.0):
    # TODO: This is generated by copilot, please check if it is correct
    """
    Computes the Van Hove correlation function for a given trajectory.
    Note that you have to provide unwrapped coordinates.

    Parameters
    ----------
    positions : np.ndarray
        trajectory array with the shape (traj_length, N, 3)
    time_log : np.ndarray
        Logarithmically saved simulation times.
    bins : int, optional
        Number of bins for the histogram. The default is 100.
    rmax : float, optional
        Maximum distance for the histogram. The default is 8.0.

    Returns
    -------
    r : np.ndarray
        Grid points of the Van Hove correlation function.
    g_r : np.ndarray
        The Van Hove correlation function.
    """

    r_max = rmax
    r_min = 0.0
    dr = (r_max - r_min) / bins
    r = np.linspace(r_min, r_max, bins)

    # Compute the distance matrix
    distance_matrix = np.linalg.norm(positions[1:] - positions[0], axis=2)

    # Compute the histogram
    g_r, _ = np.histogram(distance_matrix, bins=bins, range=(r_min, r_max))

    # Normalize the histogram
    volume = 4.0 / 3.0 * np.pi * (r_max**3 - r_min**3)
    n_particles = positions.shape[1]
    g_r = g_r / (n_particles * volume)

    return r, g_r


def get_k_vectors(
    ktarget, box_length, max_points=1000, save_vectors=False,
):
    k_step = 2 * np.pi / box_length
    k_discrete = ktarget / k_step
    k_max = int(np.ceil(k_discrete))

    # Generate all possible k-indices within the range
    n_values = np.arange(-k_max, k_max + 1)
    k_indices = np.array(list(product(n_values, repeat=3)))

    # Compute magnitudes and filter
    k_magnitudes = np.linalg.norm(k_indices, axis=1)
    close_to_k_discrete = np.abs(k_magnitudes - k_discrete) < 0.1
    valid_indices = k_indices[close_to_k_discrete]

    # Compute actual k-vectors
    k_vectors = valid_indices * k_step

    # Sample if necessary
    if len(k_vectors) > max_points:
        np.random.seed(1)
        k_vectors = k_vectors[np.random.choice(len(k_vectors), max_points, replace=False)]

    if save_vectors:
        np.save("k_vectors.npy", k_vectors)

    return k_vectors


def compute_fskt(positions, k_vectors):
    dr = positions[1:] - positions[0]
    dr_k = np.dot(dr, k_vectors.T)
    fskt = np.mean(np.cos(dr_k), axis=(1, 2))
    return fskt


def compute_fskt_batched(positions, k_vectors, batch_size=100):
    num_batches = int(np.ceil(len(k_vectors) / batch_size))
    fskt = np.zeros(positions.shape[0] - 1)
    for i in range(num_batches):
        k_batch = k_vectors[i * batch_size : (i + 1) * batch_size]
        dr_k = np.dot(positions[1:] - positions[0], k_batch.T)
        fskt_batch = np.mean(np.cos(dr_k), axis=(1, 2))
        fskt += fskt_batch * len(k_batch)
    fskt /= len(k_vectors)
    return fskt

def chi_squared(observed, expected, scaling):
    return ((observed - expected) ** 2 / scaling).sum()


def oneparam_fit(function, x, y):
    """
    Performs a fit on (x, y) as the specified function with one fit parameter
    Returns fitted parameter and quality factor q
    """

    popt, _ = curve_fit(function, x, y)
    p = popt[0]

    yexp = function(x, p)
    chi2 = chi_squared(y, yexp, yexp)
    dof = len(x) - 1
    if chi2 <= 0:
        q = 1.0
    else:
        q = 1 - gammainc(dof / 2.0, chi2 / 2.0)

    return p, q


def fit_msd_with_quality_control(t, msd, msd_std, plot=False, title="MSD"):
    """
    Increases begin point of fitting (time_log, msd) until quality factor
    is above a 1/2. Returns 3D diffusion coefficient and its uncertainty
    """

    def linear(x, b):
        return x + b

    def diffusion(t, D):
        return 6 * D * t

    log_t = np.log10(t)  # TODO: Add a checkpoint to prevent zeros in these arrays
    log_msd = np.log10(msd)

    # compute bounds of std
    msd_min = msd - msd_std
    msd_max = msd + msd_std

    # loop over begin points and compute fit until quality factor >1/2
    j = -1
    Q = 0
    while Q < 1 / 2:
        j += 1
        t_selection = log_t[j:]
        msd_selection = log_msd[j:]
        _, Q = oneparam_fit(linear, t_selection, msd_selection)

    # perform fitting on linear to obtain D and its bounds
    D, _ = oneparam_fit(diffusion, t[j:], msd[j:])
    D_min, _ = oneparam_fit(diffusion, t[j:], msd_min[j:])
    D_max, _ = oneparam_fit(diffusion, t[j:], msd_max[j:])

    D_sigma = (D_max - D_min) / 2
    D_unc = D_sigma / np.sqrt(len(log_msd) - 1)

    return D, D_unc


def fit_line_with_fixed_slope(x, y):
    """
    Fit a straight line to data points by forcing the slope to 1.
    
    Parameters:
    x (array-like): Independent variable data points.
    y (array-like): Dependent variable data points.
    
    Returns:
    float: The y-intercept of the fitted line.
    """
    x = np.array(x)
    y = np.array(y)
    
    # Calculate the y-intercept b
    b = np.mean(y - x)
    
    return b


def compute_vacf(velocities):
    """
    Computes the velocity autocorrelation function for a given trajectory.

    Parameters
    ----------
    velocities : np.ndarray
        trajectory array with the shape (traj_length, N, 3)

    Returns
    -------
    vacf : np.ndarray
        Velocity autocorrelation function -> len (traj_length - 1)
    """
    v0 = velocities[0] 
    v0_dot = np.sum(v0 * v0)

    dot_products = np.einsum('ij,tij->t', v0, velocities)

    vacf = dot_products / v0_dot
    
    return vacf

